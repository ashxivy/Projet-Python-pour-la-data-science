{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les indicateurs alimentaires permettent-il de mieux manger ?\n",
    "\n",
    "## Introduction \n",
    "\n",
    "À l'heure où la société contemporaine connaît une période d'abondance alimentaire, les préoccupations environnementales croissantes et les impératifs de santé publique rendent parfois le choix de l'alimentation difficile pour le consomateur. Des indicateurs alimentaires sont alors apparus pour guider le public vers des produits jugées bénéfiques pour leur santé et l'état de la planète. Trois indicateurs se sont imposés en France, chacun considérant une dimension de la qualité d'un aliment. Le plus utilisé est le Nutriscore, qui est un indicateur nutritionel. L'Ecoscore renseigne sur l'impact environnemental et le score NOVA est informe sur le degré de transformation des aliments. \n",
    "\n",
    "Apparu au cours de la dernière décennie, ces indicateurs nutritionnels se sont révélés être des outils précieux des politiques publiques, qui ne rechignent pas à les utiliser. Ainsi l'affichage du nutriscore a été mis en place par le gouvernement français en 2016. Néanmoins la santé alimentaire ne semble pas s'être amélioré significativement depuis la mise en place de ces indicateurs. Cela nous amène à nous demander si ces indicateurs ont réellement un effet bénéfique sur le consommateur. \n",
    "\n",
    "Nous allons utiliser les données de la base Open Food Fact afin de mener une étude à ce sujet.\n",
    "Dans un premier temps, nous allons télécharger la base et la nettoyer, afin de résoudre les problèmes liés à l'Open Data (Partie I). Puis nous avec l'aide d'analyses graphiques (Partie II), nous commencerons à formuler des hypothèses, auquelles nous répondrons à l'aide de modélisation (Partie III)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie I : Récupération et nettoyage des données de la base Open Food Fact\n",
    "\n",
    "# Partie I.1 : Présentation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie I.1.1 Présentation Open Food Fact\n",
    "\n",
    "présenter les données plus dico des variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Nutri-score est un système d'étiquetage nutritionnel à cinq niveaux, allant de A à E et du vert au rouge, placé sur le devant des emballages alimentaires, établi en fonction de la valeur nutritionnelle d'un produit alimentaire. Il a pour but d'aider les consommateurs à reconnaitre la qualité nutritionnelle globale des aliments et les aider à comparer les aliments entre eux, afin de favoriser le choix de produits plus favorable à la santé et ainsi de participer à la lutte contre les maladies chroniques comme les maladies cardiovasculaires, certains cancers, l'obésité et le diabète."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous souhaitons ici tenter de retrouver les principaux critères du Nutri-Score en regressant la valeur du nutri-score sur plusieurs variables qualitatives nutritionnelles. \n",
    "Puis nous aimerions élargir notre angle d'études en considérant d'autres critères pour quantifier la qualité d'un produit alimentaire (son niveau de transformation et sa provenance notamment). Nous crérons des scoring pour chacune des variables qu'on travaillerait. \n",
    "Enfin, nous aimerions mettre en évidence les différents catégories de produits alimentaires en utilisant des algorithmes de clustering à partir de nos scorings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous travaillerons sur la base de donnée OpenFoodFacts. Open Food Facts est un projet collaboratif dont le but est de constituer une base de données libre et ouverte sur les produits alimentaires commercialisés dans le monde entier. \n",
    "La première étape de notre projet est donc de nettoyer cette base de donnée très dense afin de pouvoir commencer nos analyses. \n",
    "Nous bornerons notre étude aux produits vendus en France, en ne gardant que les variables qui nous intéressent, pour cela on gardera les produits alimentaires qui auront toutes les variables d'intérêts renseignées.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie I.1.3 : Nova-Score et l'Ecosore\n",
    "\n",
    "L'Éco-Score évalue l'impact environnemental des produits alimentaires en prenant en compte des critères écologiques variés tels que l'utilisation des terres, les émissions de gaz à effet de serre et la consommation d'eau. Il vise à sensibiliser les consommateurs aux implications environnementales de leurs choix alimentaires en attribuant une note qui permet de comparer la performance écologique des produits.\n",
    "\n",
    "\n",
    "\n",
    "Le Score NOVA classe les produits alimentaires en fonction du degré de transformation qu'ils ont subi, allant de 1 à 4. Il prend en considération des critères tels que la nature des ingrédients, le degré de transformation, la présence d'additifs et la similitude avec des aliments non transformés. Cette classification encourage les consommateurs à opter pour des aliments moins transformés et plus proches de leur état naturel, mettant en avant les potentiels impacts sur la santé associés à la consommation d'aliments fortement transformés.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe les librairies Python qu'on utilisera dans le projet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On importe les modules nécessaires au traitement de la base et communiquer les données\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#On importe les modules utilsés pour la modélisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe la base de donnée OpenFoodFacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier CSV\n",
    "url_path = 'https://www.data.gouv.fr/fr/datasets/r/164c9e57-32a7-4f5b-8891-26af10f91072'\n",
    "# Charger le fichier CSV dans un DataFrame pandas\n",
    "df_openfoodfacts = pd.read_csv(url_path, sep='\\t',low_memory=True)  # Assurez-vous de spécifier le bon séparateur s'il est différent de la virgule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut connaître ses dimensions avant nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On vérifie que la base est bien chargée\n",
    "#on affiche 5 lignes aléatoires \n",
    "print(df_openfoodfacts.sample(5))\n",
    "\n",
    "#on veut connaître la taille de la base\n",
    "print (\"Le dataframe compte {} lignes et {} variables\".format(df_openfoodfacts.shape[0], df_openfoodfacts.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence le nettoyage de la base de donnée OpenFoodFacts: on ne garde que les produits qui sont vendus uniquement en France "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtention des valeurs distinctes de la colonne 'countries_tags' sans les valeurs nulles\n",
    "valeurs_distinctes =df_openfoodfacts['countries_tags'].dropna().drop_duplicates().tolist()\n",
    "\n",
    "# Tri des valeurs distinctes en ordre alphabétique\n",
    "valeurs_distinctes.sort()\n",
    "\n",
    "for valeur in valeurs_distinctes:\n",
    "    print(valeur)\n",
    "\n",
    "#On remarque que la France apparrait sous différentes formes, comme \"fr:France\", \"en:France\" ou encore \"de:Frankreich\".\n",
    "#un peu de travail est nécéssaire pour récupérer tous les produits vendus en France\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons obtenu la liste des pays où chaque produit est vendu. Au reagrd de la très grande diversité des produits et des pays de vente, nous avons décidé de se concentrer uniquement sur les produits vendus sur un seul marché, ici la France. \n",
    "\n",
    "Ce choix est pertinent pour plusieurs raisons . La France est en effet un pays où les étiquetages alimenataires sont très répandus et sont intégrés aux politiques publiques. De plus, les observations de produits français sont très présent dans la base Open food fact. Cela s'explique par l'origine hexagonale du projet et des campagnes de collectes de données menées par l'Agence Santé France.\n",
    "\n",
    "En se focalisant sur les produits vendus en France, notre analyse se concentre de manière exclusive sur un marché unique. Cette approche garantit une comparaison pertinente entre les produits, facilitant ainsi l'interprétation des résultats. En outre, elle permet de maintenir la cohérence des données tout en assurant un volume suffisant pour des analyses approfondies.\n",
    "\n",
    "On ne conserve ainsi que les produits uniquement vendus en France. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer le DataFrame pour ne conserver que les lignes avec 'en:france' dans la colonne 'countries_tags'\n",
    "df_france = df_openfoodfacts[df_openfoodfacts['countries_tags'] == 'en:france']\n",
    "# Afficher les premières lignes du DataFrame résultant\n",
    "print(df_france.head())\n",
    "\n",
    "#on veut connaître la taille de la base\n",
    "print (\"Le dataframe compte {} lignes et {} variables\".format(df_france.shape[0], df_france.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer le DataFrame pour ne conserver que les lignes avec 'en:france' dans la colonne 'countries_tags'\n",
    "df_france = df_openfoodfacts[df_openfoodfacts['countries_tags'] == 'en:france']\n",
    "# Afficher les premières lignes du DataFrame résultant\n",
    "print(df_france.head())\n",
    "\n",
    "#on veut connaître la taille de la base\n",
    "print (\"Le dataframe compte {} lignes et {} variables\".format(df_france.shape[0], df_france.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On souhaite visualiser d'un coup d'oeil les variables d'intérêt de la base de donnée: quelles variables pourrons nous être utiles pour notre analyse? lesquelles sont assez remplies pour nous être utiles? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On calcule le taux de remplissage de chaque variable\n",
    "def null_factor(df):\n",
    "  null_rate = ((df.isnull().sum() / df.shape[0])*100).sort_values(ascending=False).reset_index()\n",
    "  null_rate.columns = ['Variable','Taux_de_Null']\n",
    "  return null_rate\n",
    "\n",
    "#Nous alllons désormais commencer à nettoyer la base de données en enlevant les colonnes peu remplis. \n",
    "filling_features = null_factor(df_france)\n",
    "filling_features[\"Taux_de_Null\"] = 100-filling_features[\"Taux_de_Null\"]\n",
    "filling_features = filling_features.sort_values(\"Taux_de_Null\", ascending=False) \n",
    "\n",
    "#Seuil de suppression\n",
    "sup_threshold = 10\n",
    "\n",
    "#On affiche le taux de remplissages des variables en fonction d'un seuil de référence\n",
    "fig = plt.figure(figsize=(20, 35))\n",
    "\n",
    "font_title = {'family': 'serif',\n",
    "              'color':  '#114b98',\n",
    "              'weight': 'bold',\n",
    "              'size': 18,\n",
    "             }\n",
    "\n",
    "sns.barplot(x=\"Taux_de_Null\", y=\"Variable\", data=filling_features, palette=\"flare\")\n",
    "#Seuil pour suppression des varaibles\n",
    "plt.axvline(x=sup_threshold, linewidth=2, color = 'r')\n",
    "plt.text(sup_threshold+2, 65, 'Seuil de suppression des variables', fontsize = 16, color = 'r')\n",
    "\n",
    "plt.title(\"Taux de remplissage des variables dans le jeu de données (%)\", fontdict=font_title)\n",
    "plt.xlabel(\"Taux de remplissage (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va supprimer les colonnes qui ne sont pas remplies à + de 10% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On ne décide de ne garder que les colonnes remplis à plus de 10%\n",
    "seuil = 10  \n",
    "filled_variables = list(filling_features.loc[filling_features['Taux_de_Null'] >= seuil, 'Variable'].values)\n",
    "\n",
    "#Nouveau Dataset avec les variables conservées\n",
    "df_france = df_france[filled_variables]\n",
    "\n",
    "# Affichage du résultat\n",
    "print (\"Le dataframe df_france compte {} lignes et {} variables\".format(df_france.shape[0], df_france.shape[1]))\n",
    "\n",
    "for column_name in df_france.columns:\n",
    "    print(column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On allège de nouveau la base de donnée en enlevant les variables qui ne nous intéressent pas pour la suite (celles qui contiennent des images des produits notamment par exemple et qui consomment beaucoup de place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On supprime les variables inutiles pour le reste du projet pour alléger la base\n",
    "useless_columns = [col for col in df_france.columns if 'url' in col or 'image' in col or \"categories\" in col or \"last\" in col or \"states\" in col or \"creator\" in col ]\n",
    "df_france = df_france.drop(columns=useless_columns)\n",
    "\n",
    "print (\"Le dataframe df_france compte {} lignes et {} variables\".format(df_france.shape[0], df_france.shape[1]))\n",
    "\n",
    "#On affiche le nom des colonnes restantes\n",
    "for column_name in df_france.columns:\n",
    "    print(column_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On ne garde que les observations où les informations nutritionneles sont complétées  \n",
    "\n",
    "\n",
    "df_france = df_france[(df_france['nutriscore_grade'].notnull()) & (df_france['ecoscore_grade'].notnull()) & (df_france['fiber_100g'].notnull()) & (df_france['energy_100g'].notnull()) & (df_france['saturated-fat_100g'].notnull())  & (df_france['sugars_100g'].notnull())  & (df_france['proteins_100g'].notnull()) & (df_france['fat_100g'].notnull()) & (df_france['salt_100g'].notnull()) & (df_france['carbohydrates_100g'].notnull()) & (df_france['sodium_100g'].notnull())]\n",
    "\n",
    "print(df_france.describe())\n",
    "\n",
    "print (\"Le dataframe df_france compte {} lignes et {} variables\".format(df_france.shape[0], df_france.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On continue le nettoyage de la base en enlevant les valeurs abérrantes\n",
    "#Open food fact est une base open source ouverte à tous. Il n'est pas abérrant de penser que des erreurs ont pu se produire lors  de l'entrée de certaines données\n",
    "\n",
    "def suppression_aberrations(df):\n",
    "    # Cette fonction supprime les observations où les valeurs sont aberrantes\n",
    "\n",
    "    var_pour_100g = ['fat_100g', 'saturated-fat_100g', 'carbohydrates_100g', 'sugars_100g', 'fiber_100g', 'proteins_100g', 'salt_100g', 'sodium_100g']\n",
    "\n",
    "    for var in var_pour_100g:\n",
    "        df = df[(df[var] >= 0) & (df[var] <= 100)]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On regarde combien d'observations étaient abérrantes\n",
    "\n",
    "ni=df_france.shape[0] \n",
    "\n",
    "# Appliquer la fonction sur le DataFrame\n",
    "df_france = suppression_aberrations(df_france)\n",
    "\n",
    "nf=df_france.shape[0]\n",
    "\n",
    "delta_lignes=ni-nf #Controle du nombre de lignes supprimées \n",
    "\n",
    "print(delta_lignes,\"lignes considérées comme des abérrations et donc supprimées\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformons le Nutriscore et l'ecoscore en variable quantitative, ce qui sera utile pour faire des régressions\n",
    "def convertion_num_score(lettre):\n",
    "    if lettre ==\"a\":\n",
    "        score=1\n",
    "    elif lettre == \"b\":\n",
    "        score=2\n",
    "    elif lettre == \"c\":\n",
    "        score=3\n",
    "    elif lettre == \"d\":\n",
    "        score=4\n",
    "    elif lettre == \"e\":\n",
    "        score=5\n",
    "    else:\n",
    "        score=np.nan\n",
    "    return score\n",
    "\n",
    "df_france[\"nutriscore_num\"]=df_france['nutriscore_grade'].apply(convertion_num_score)\n",
    "df_france[\"ecoscore_num\"]=df_france['ecoscore_grade'].apply(convertion_num_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On affiche des informations sur la base finale\n",
    "\n",
    "filling_features = null_factor(df_france)\n",
    "filling_features[\"Taux_de_Null\"] = 100-filling_features[\"Taux_de_Null\"]\n",
    "filling_features = filling_features.sort_values(\"Taux_de_Null\", ascending=False) \n",
    "fig = plt.figure(figsize=(20, 35))\n",
    "\n",
    "font_title = {'family': 'serif',\n",
    "              'color':  '#114b98',\n",
    "              'weight': 'bold',\n",
    "              'size': 18,\n",
    "             }\n",
    "\n",
    "sns.barplot(x=\"Taux_de_Null\", y=\"Variable\", data=filling_features, palette=\"flare\")\n",
    "#Seuil pour suppression des varaibles\n",
    "plt.axvline(x=sup_threshold, linewidth=2, color = 'r')\n",
    "plt.text(sup_threshold+2, 65, 'Seuil de suppression des variables', fontsize = 16, color = 'r')\n",
    "\n",
    "plt.title(\"Taux de remplissage des variables dans le jeu de données (%)\", fontdict=font_title)\n",
    "plt.xlabel(\"Taux de remplissage (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtention des valeurs distinctes de la colonne 'countries_tags' sans les valeurs nulles\n",
    "valeurs_distinctes = df_france['popularity_tags'].dropna().drop_duplicates().tolist()\n",
    "\n",
    "# Tri des valeurs distinctes en ordre alphabétique\n",
    "valeurs_distinctes.sort()\n",
    "\n",
    "for valeur in valeurs_distinctes:\n",
    "    print(valeur)\n",
    "\n",
    "#On remarque que la France apparrait sous différentes formes, comme \"fr:France\", \"en:France\" ou encore \"de:Frankreich\".\n",
    "#un peu de travail est nécéssaire pour récupérer tous les produits vendus en France\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On réalise désormais des statistiques descriptives \n",
    "On commence par étudier le Nutriscore, qui est le principal score utilisé pour déterminer la qualitée nutritionnelles \n",
    "\n",
    "On commence par montrer la répartition du score du Nutriscore dans la base. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_pie(score):\n",
    "    # Filtrer les données pour exclure la catégorie 'Unknown' et 'non-applicable'\n",
    "\n",
    "    filtered_data = df_france[(df_france[score] != 'unknown') & (df_france[score] != 'not-applicable')]\n",
    "\n",
    "    # Compter les occurrences des valeurs dans la colonne 'nutriscore_grade' et trier par index (ordre alphabétique)\n",
    "    score_counts = filtered_data[score].value_counts().sort_index()\n",
    "\n",
    "    nutriscore_colors = {'a': '#2ecc71', 'b': '#55efc4', 'c': '#f4d03f', 'd': '#e67e22', 'e': '#e74c3c', '1.0': '#2ecc71', '2.0': '#f4d03f', '3.0': '#e67e22', '4.0': '#e74c3c'}\n",
    "    colors = [nutriscore_colors.get(str(category), '#95a5a6') for category in score_counts.index]\n",
    "\n",
    "    # Créer le diagramme circulaire avec les couleurs spécifiques du Nutri-Score\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(score_counts, labels=score_counts.index, autopct='%1.1f%%', startangle=9, colors=colors)\n",
    "    score_name = score.split(\"_\")\n",
    "    plt.title('Répartition du score ' + score_name[0])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#On affiche les différentes scores\n",
    "plot_pie(\"nutriscore_grade\")\n",
    "plot_pie(\"ecoscore_grade\")\n",
    "plot_pie(\"nova_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_evolution(score):\n",
    "\n",
    "    # Make sure the 'created_datetime' column is in datetime format\n",
    "    df_france['created_datetime'] = pd.to_datetime(df_france['created_datetime'])\n",
    "\n",
    "    # Filtrer les données pour exclure la catégorie 'Unknown' et 'non-applicable'\n",
    "    filtered_data = df_france[(df_france[score] != 'unknown') & (df_france[score] != 'not-applicable')]\n",
    "\n",
    "    # Make sure the 'created_datetime' column is in datetime format\n",
    "    df_france['created_datetime'] = pd.to_datetime(df_france['created_datetime'])\n",
    "\n",
    "\n",
    "    # Extract year from the 'created_datetime' column\n",
    "    filtered_data['year'] = filtered_data['created_datetime'].dt.year\n",
    "\n",
    "    # On crée un nouveau dataframe pour manipuler les données utiles pour le graphique\n",
    "    cumulative_df = pd.DataFrame(index=filtered_data['year'].unique(), columns=filtered_data[score].unique())\n",
    "\n",
    "    # On calcule le nombre d'occurences par note et par an \n",
    "    for year in cumulative_df.index:\n",
    "        year_data = filtered_data[filtered_data['year'] <= year]\n",
    "        counts = year_data[score].value_counts(normalize=True) * 100  # Calculate percentages\n",
    "        cumulative_df.loc[year] = counts\n",
    "\n",
    "    # On affiche les années dans l'ordre\n",
    "    cumulative_df.sort_index(inplace=True)\n",
    "    cumulative_df = cumulative_df[sorted(cumulative_df.columns)]\n",
    "\n",
    "\n",
    "    #On affiche le graphique \n",
    "    nutriscore_colors = {'a': '#2ecc71', 'd': '#55efc4', 'c': '#f4d03f', 'b': '#e67e22', 'e': '#e74c3c',\n",
    "                         '1.0': '#2ecc71', '2.0': '#f4d03f', '3.0': '#e67e22', '4.0': '#e74c3c'}\n",
    "\n",
    "    colors = [nutriscore_colors.get(str(category), '#95a5a6') for category in counts.index]\n",
    "\n",
    "    cumulative_df.plot(kind='bar', stacked=True, figsize=(10, 6), color=colors)\n",
    "    \n",
    "    #On affiche le titre et la légende\n",
    "    score_name = score.split(\"_\")\n",
    "    plt.title('Répartition du score ' + score_name[0]) \n",
    "    plt.legend(title='Grade', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.ylabel('Pourcentage')\n",
    "    plt.xlabel('Années')\n",
    "    plt.yticks(range(0, 101, 10), [f'{i}%' for i in range(0, 101, 10)])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "time_evolution(\"nutriscore_grade\")\n",
    "time_evolution(\"ecoscore_grade\")\n",
    "time_evolution(\"nova_group\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_creation_time(score):\n",
    "\n",
    "    filtered_data = df_france[(df_france[score] != 'unknown') & (df_france[score] != 'not-applicable')]\n",
    "\n",
    "    score_per_year = filtered_data[['code', score]].groupby(by=[score,filtered_data['created_datetime'].dt.year]).nunique().reset_index()\n",
    "    cum_per_year = filtered_data[['code']].groupby(by=filtered_data['created_datetime'].dt.year).nunique().reset_index()\n",
    "    score_per_year = pd.merge(score_per_year, cum_per_year, how=\"left\", left_on=\"created_datetime\", right_on=\"created_datetime\")\n",
    "    score_per_year = score_per_year.rename(columns={'created_datetime':'year', 'code_x':'nb_score', 'code_y':'total_grade'})\n",
    "    score_per_year['score_rate'] = (score_per_year['nb_score'] / score_per_year['total_grade'])*100\n",
    "\n",
    "\n",
    "    nutriscore_colors = {'a': '#2ecc71', 'd': '#55efc4', 'c': '#f4d03f', 'b': '#e67e22', 'e': '#e74c3c',\n",
    "                         '1.0': '#2ecc71', '2.0': '#f4d03f', '3.0': '#e67e22', '4.0': '#e74c3c'}\n",
    "    \n",
    "    colors = [nutriscore_colors.get(str(category), '#95a5a6') for category in score_per_year[score].index]\n",
    "\n",
    "    fig =plt.figure(figsize=(12,8))\n",
    "    ax = sns.lineplot(x='year', y='score_rate', hue=score, data=score_per_year, palette = colors)\n",
    "    plt.xlabel(\"Année\")\n",
    "    plt.ylabel(\"Taux\")\n",
    "\n",
    "    score_name = score.split(\"_\")\n",
    "    plt.title('2volution des entrées des nouveaux scores ' + score_name[0]) \n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "new_creation_time(\"nutriscore_grade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On affiche la répartition du score brut du nutriscore, avant transformation en grade\n",
    "\n",
    "# Filtrer les données pour exclure la catégorie 'Unknown' et 'non-applicable'\n",
    "filtered_data = df_france[(df_france[\"nutriscore_grade\"] != 'unknown') & (df_france[\"nutriscore_grade\"] != 'not-applicable')]\n",
    "\n",
    "    \n",
    "fig, axes = plt.subplots(1, 2, sharex=False, sharey=False, figsize=(21,8))\n",
    "fig.suptitle(\"Répartition des scores Nutriscore et de leurs grades\" \"\\n\", fontdict=font_title)\n",
    "\n",
    "sns.histplot(data=filtered_data.sort_values(\"nutriscore_grade\"), x=\"nutriscore_grade\", hue=\"nutriscore_grade\", ax=axes[0])\n",
    "axes[0].set_title('Grades de Nutriscores')\n",
    "axes[0].set_xlabel(\"Grade Nutriscore\")\n",
    "axes[0].set_ylabel(\"Nombre de produits\")\n",
    "\n",
    "\n",
    "sns.histplot(data=filtered_data.sort_values(\"nutriscore_grade\"), x=\"nutriscore_score\", hue=\"nutriscore_grade\", ax=axes[1])\n",
    "axes[1].set_title('Scores de Nutriscores')\n",
    "axes[1].set_xlabel(\"Score Nutriscore\")\n",
    "axes[1].set_ylabel(\"Nombre de produits\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On étudie la qualité de la nourriture sous 3 aspects : écologie, nutritionelles et transformations. \n",
    "On va utiliser une heatmap pour voir s'il n'existe pas déjà des corrélations entre les variables\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['additives_n','energy_100g', 'fat_100g'\n",
    "        , 'saturated-fat_100g', 'carbohydrates_100g',\n",
    "       'sugars_100g', 'fiber_100g', 'proteins_100g', 'salt_100g',\n",
    "       'sodium_100g', 'nutriscore_num', 'ecoscore_num', 'nova_group']\n",
    "\n",
    "x=df_france.loc[:, variables]\n",
    "x = x.dropna()\n",
    " \n",
    "#calculate the correlation matrix\n",
    "corr = x.corr()\n",
    "\n",
    "lab=x.columns\n",
    "#plot the heatmap\n",
    "fig=plt.figure(figsize=[12,9])\n",
    "fig.patch.set_facecolor('#E0E0E0')\n",
    "fig.patch.set_alpha(0.7)\n",
    "\n",
    "plt.title(\"Correlation linéaire entre les variables\",size=18)\n",
    "ax=sns.heatmap(corr, vmin=-1, vmax=1,cmap=\"bwr\",\n",
    "        xticklabels=variables,\n",
    "        yticklabels=variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "II. Partie analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant créer une base de donnée unifiée qui ne contient que les variables d'intérêt pour la suite où toutes les occurences pour les scorings créés après sont renseignés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les lignes où 'labels_tags' et 'ingredients_text' ne sont pas nulles\n",
    "df_filtered = df_cleaned.dropna(subset=['labels_tags', 'ingredients_text'])\n",
    "\n",
    "# Sélectionner les colonnes spécifiques\n",
    "selected_columns = ['code', 'countries_tags', 'ecoscore_grade', 'nutriscore_grade', 'product_name',\n",
    "                     'energy_100g', 'saturated-fat_100g', 'sugars_100g', 'proteins_100g',\n",
    "                     'fat_100g', 'carbohydrates_100g', 'energy-kcal_100g', 'sodium_100g', 'salt_100g',\n",
    "                     'food_groups_tags', 'labels_tags', 'nutriscore_score', 'nutrition-score-fr_100g',\n",
    "                     'ecoscore_score', 'ingredients_text', 'nova_group', 'fiber_100g']\n",
    "\n",
    "# Créer le DataFrame final\n",
    "df_selected = df_filtered[selected_columns]\n",
    "\n",
    "# Afficher le DataFrame résultant\n",
    "df_selected\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Le dataframe df_cleaned compte {} lignes et {} variables\".format(df_selected.shape[0], df_selected.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de cette liste, en modifiant à la main, on va garder uniquement les variables que je souhaite étudier pour la suite. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va désormais élargir notre analyse en prenant en compte de nouveaux critères qui sont importants lorsqu'on souhaite mieux s'alimenter: le degré de transformation, les additifs et la provenance des produits. On va essayer de créé des variables de scoring pour ces trois catégories avant de faire une comparaison avec le Nutri-Score étudié au dessus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Analyse du degré de transformation\n",
    "\n",
    "Pour cette variable, le principal problème est la quantification de la transformation du produit alimentaire. Une approche simple serait de considérer que plus un produit alimentaire contient d'ingrédient, plus il est transformé. \n",
    "\n",
    "En s'appuyant sur les critères du nova-score, on va essayer de reproduire son scoring en appliquant les critères décrits ici: https://scanup.fr/degre-de-transformation-des-aliments-la-classification-nova/ .\n",
    "\n",
    "D'abord, on va donc identifier les produits de la base qui correspondent à des produits naturels (fruits, légumes, poisson qui sont tels quels) en utilisant la catégorie food_groups_tags, avant de faire une analyse des ingrédients sur les produits qu'on identifie comme étant non bruts. \n",
    "On observe sur le graphique généré précédemment qu'environ 30% des produits ont la variable ingredient_text renseigné, ce qui nous permettra de générer un nova score sur environ 30% des produits de la base. \n",
    "La variable food_groups_tags nous permettra de corriger les cas déviants les plus problématiques après la première étape de scoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les valeurs uniques de la colonne 'main_category_fr'\n",
    "valeurs_main_category_fr = df_selected['food_groups_tags'].unique()\n",
    "\n",
    "# Afficher les valeurs\n",
    "print(valeurs_main_category_fr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait un premier test de scoring en prenant en compte uniquement le nombre d'ingédients listés dans le produit. On veut d'abord regarder comment la variable est renseignée pour choisir le meilleur séparateur d'ingrédiant qui pourra nous permettre de trouver le plus justement possible le nombre d'ingrédents sachant qu'à posteriori, on a vu que la variable n'était pas renseignée de manière homogène. "
    ]
    },
    {
    "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume df_france is your DataFrame with numerical features\n",
    "# Select relevant columns and handle missing values if necessary\n",
    "selected_columns = ['additives_n', 'energy_100g', 'fat_100g',\n",
    "                    'saturated-fat_100g', 'carbohydrates_100g',\n",
    "                    'sugars_100g', 'fiber_100g', 'proteins_100g', 'salt_100g',\n",
    "                    'sodium_100g', 'nutriscore_num', 'ecoscore_num', 'nova_group']\n",
    "df_selected = df_france[selected_columns].dropna()\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "df_selected_scaled = scaler.fit_transform(df_selected)\n",
    "\n",
    "# Use DBSCAN for clustering\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)  # Adjust eps and min_samples based on your data\n",
    "clusters = dbscan.fit_predict(df_selected_scaled)\n",
    "\n",
    "# Visualize the clusters (2D example)\n",
    "plt.scatter(df_selected_scaled[:, 0], df_selected_scaled[:, 1], c=clusters, cmap='viridis')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.xlabel('Feature 1 (Standardized)')\n",
    "plt.ylabel('Feature 2 (Standardized)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les valeurs uniques de la colonne 'main_category_fr'\n",
    "valeurs_main_category_fr = df_selected['ingredients_text'].unique()\n",
    "\n",
    "# Afficher les valeurs\n",
    "print(valeurs_main_category_fr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que le renseignement de la variable ingredients_text est assez hétérogène: On a donc mis en évidence plusieurs manières de comptabiliser le nb d'ingrédients:\n",
    "- en comptant le nombre de virgules dans la chaîne de caractère\n",
    "- en comptant le nombre d'espaces dans la chaîne de caractère (plus fiable mais tend à augumenter le nb d'ingrédient par rapport à la réalité)\n",
    "- le nombre de points virgule\n",
    "\n",
    "Finalement, compter les espaces est trop hazardeux, donc on va se concentrer sur le comptage des virgules. On décide donc finalement de compter la somme des virgules et des points virgules puisqu'en général, les deux séparateurs ne sont pas utilisés simultanément, donc compter leur somme nous permettra de balayer le plus de liste d'ingrédients possible tout en faussant le moins possible. \n",
    "\n",
    "Il nous restera à traiter ensuite du cas des listes d'ingrédients sans séparateurs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter le nombre d'espaces dans chaque chaîne de caractères de 'ingredients_text'\n",
    "df_selected['nombre_ingredients'] = df_selected['ingredients_text'].apply(lambda x: x.count(',') + x.count(';'))\n",
    "\n",
    "# Afficher le DataFrame avec la nouvelle colonne\n",
    "print(df_selected[['ingredients_text', 'nombre_ingredients']])\n",
    "\n",
    "# Obtenir un tableau d'occurrences du nombre d'ingrédients\n",
    "occurrences_nb_ingredients = df_selected['nombre_ingredients'].value_counts()\n",
    "\n",
    "# Afficher le tableau d'occurrences\n",
    "print(occurrences_nb_ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va établir le scoring suivant: \n",
    "- produit brut: 1 si le nombre d'ingrédients est égal à 1 ou 2; \n",
    "- ingrédient culiaire: 2 si le nom d'ingrédients est 3 ou 4; \n",
    "- produit simplement transformé: 3 si le nombre d'ingrédiants est situé entre 5 et 7 et \n",
    "- produit très transformé: 4 si le nombre d'ingrédients est au delà de 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une nouvelle colonne 'score' en fonction du nombre d'ingrédients\n",
    "df_selected['score_transformation'] = df_selected['nombre_ingredients'].apply(lambda n: 1 if n <= 2 else (2 if n <= 4 else (3 if n <= 7 else 4)))\n",
    "\n",
    "# Afficher le DataFrame avec la nouvelle colonne 'score'\n",
    "#print(df_selected[['ingredients_text', 'nombre_ingredients', 'score_transformation']])\n",
    "\n",
    "# Obtenir un tableau d'occurrences du scoring sur la transformation des produits\n",
    "occurrences_scoring_transformation = df_selected['score_transformation'].value_counts()\n",
    "\n",
    "# Afficher le tableau d'occurrences\n",
    "print(occurrences_scoring_transformation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour tester le scoring qu'on vient de créer, nous proposons de regarder les occurences de food_groups_tags qu'on retrouve parmi les produits qu'on a classé en scoring 1 pour la transformation pour voir s'il y a une certaine cohérence (nous ne sommes pas censé retrouver des buscuits par exemple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les produits avec un score de 1\n",
    "score_1_products = df_selected[df_selected['score_transformation'] == 1]\n",
    "\n",
    "# Afficher les occurrences de food_groups_tags pour les produits avec un score de 1\n",
    "occurrences_score_1 = score_1_products['food_groups_tags'].value_counts()\n",
    "\n",
    "# Afficher les résultats\n",
    "print(occurrences_score_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va vérifier les occurences étranges et voir ce qu'on peut faire pour corriger ces défauts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les produits où food_groups_tags prend la valeur \"en:sugary-snacks,en:biscuits-and-cakes\"\n",
    "filtered_products = score_1_products[score_1_products['food_groups_tags'] == 'en:sugary-snacks,en:biscuits-and-cakes']\n",
    "\n",
    "# Afficher la colonne 'product_name' des produits filtrés\n",
    "print(filtered_products[['product_name', 'ingredients_text']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, pour régler le problème des listes d'ingrédients sans séparateurs, on va utiliser la catégorie des produits transformés renseigné dans food_groups_tags pour les mettre directement en score 4, ce qui permettra d'enlever ces passagers clandestins des catégories 1, 2 et 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des catégories de produits transformés\n",
    "categorie_produits_transformes = ['en:composite-foods,en:one-dish-meals',\n",
    "                                  'en:composite-foods,en:pizza-pies-and-quiches',\n",
    "                                  'en:sugary-snacks,en:biscuits-and-cakes',\n",
    "                                  'en:salty-snacks,en:salty-and-fatty-products',\n",
    "                                  'en:salty-snacks,en:appetizers',\n",
    "                                  'en:composite-foods,en:sandwiches',\n",
    "                                  'en:sugary-snacks,en:chocolate-products']\n",
    "\n",
    "# Mise à jour du score pour les produits dans la liste des catégories de produits transformés\n",
    "df_selected.loc[df_selected['food_groups_tags'].isin(categorie_produits_transformes), 'score_transformation'] = 4\n",
    "\n",
    "# Afficher le DataFrame mis à jour\n",
    "print(df_selected[['product_name', 'food_groups_tags', 'score_transformation']])\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume df_france is your DataFrame with the relevant columns\n",
    "# Select relevant columns and handle missing values if necessary\n",
    "selected_columns = ['nova_group', 'nutriscore_num', \"ecoscore_num\"]\n",
    "df_selected = df_france[selected_columns].dropna()\n",
    "\n",
    "# Define the independent variable (X) and the dependent variable (y)\n",
    "X = df_selected[['nutriscore_num', \"ecoscore_num\"]]\n",
    "y = df_selected['nova_group']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Coefficient for 'nutriscore_num':\", model.coef_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On refait un test pour voir si les scorings 1 clandestins ont été corrigés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume df_france is your DataFrame with the relevant columns\n",
    "# Select relevant columns and handle missing values if necessary\n",
    "selected_columns = ['nova_group', 'nutriscore_num']\n",
    "df_selected = df_france[selected_columns].dropna()\n",
    "\n",
    "# Define the independent variable (X) and the dependent variable (y)\n",
    "X = df_selected[['nutriscore_num']]\n",
    "y = (df_selected['nova_group'] > 0).astype(int)  # Convert to binary outcome (0 or 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a logistic regression model\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Plot the coefficients\n",
    "plt.bar(X.columns, logreg_model.coef_[0])\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title('Coefficients of Logistic Regression')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les produits avec un score de 1\n",
    "score_1_products = df_selected[df_selected['score_transformation'] == 1]\n",
    "\n",
    "# Afficher les occurrences de food_groups_tags pour les produits avec un score de 1\n",
    "occurrences_score_1 = score_1_products['food_groups_tags'].value_counts()\n",
    "\n",
    "# Afficher les résultats\n",
    "print(occurrences_score_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Origine des aliments \n",
    "\n",
    "On va maintenant s'intéresser aux labels des produits alimentaires qu'on considère grâce à la variable labels_tags et tenter de faire une variable de scoring qui nous permettrait de quantifier sa qualité en fonction des labels qu'on lui a accordé quant à sa provenance ou sa production (étiquette bio ou made in France notamment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les occurrences qui apparaissent plus de 1000 fois dans la colonne 'labels_tags'\n",
    "occurrences_plus_de_1000 = df_selected['labels_tags'].value_counts()[df_selected['labels_tags'].value_counts() > 1000]\n",
    "\n",
    "# Afficher le tableau d'occurrences\n",
    "print(occurrences_plus_de_1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va considérer le scoring suivant pour quantifier l'origine et la provenance des produits alimentaires. \n",
    "On se basera sur la provenance (France/UE) et la catégorie de bio \n",
    "On définera les scores suivants:\n",
    "- 1 si le produit est français et bio \n",
    "- 2 si le produit est européen et bio \n",
    "- 3 si le produit est français\n",
    "- 4 si le produit est bio \n",
    "- 5 sinon \n",
    "\n",
    "On a choisi de faire du plus petit au plus grand pour décrire l'évolution du \"meilleur\" au \"pire\" pour se caler sur la logique du nutriscore, ce qui nous facilitera les comparaisons par la suite. \n",
    "\n",
    "Pour mesurer les différents attributs, on va faire uen analyse dans les chaînes de caractère des labels: s'il y a france ou fr on lui attribuera le fait qu'il est français par exemple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une nouvelle colonne 'score_labels' initialisée à 0\n",
    "df_selected['score_labels'] = 0\n",
    "\n",
    "# Définir des critères et attribuer des scores\n",
    "critere_bio_france = df_selected['labels_tags'].str.contains('france|fr', case=False) & df_selected['labels_tags'].str.contains('bio|organic', case=False)\n",
    "critere_eu_bio = df_selected['labels_tags'].str.contains('eu', case=False) & df_selected['labels_tags'].str.contains('bio|organic', case=False)\n",
    "critere_france = df_selected['labels_tags'].str.contains('france|fr', case=False)\n",
    "critere_bio = df_selected['labels_tags'].str.contains('bio|organic', case=False)\n",
    "\n",
    "# Attribuer des scores en fonction des critères (inverser l'ordre)\n",
    "df_selected.loc[~(critere_bio_france | critere_eu_bio | critere_france | critere_bio) & (df_selected['score_labels'] < 1), 'score_labels'] = 5\n",
    "df_selected.loc[critere_bio & (df_selected['score_labels'] < 2), 'score_labels'] = 4\n",
    "df_selected.loc[critere_france & (df_selected['score_labels'] < 3), 'score_labels'] = 3\n",
    "df_selected.loc[critere_eu_bio & (df_selected['score_labels'] < 4), 'score_labels'] = 2\n",
    "df_selected.loc[critere_bio_france, 'score_labels'] = 1\n",
    "\n",
    "# Afficher le DataFrame avec la nouvelle colonne de scoring\n",
    "print(df_selected[['labels_tags', 'score_labels']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected",
    "print(df_selected_scaled_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
